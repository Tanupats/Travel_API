from fastapi import FastAPI, File, UploadFile
app = FastAPI()


# -*- coding: utf-8 -*-
"""APIIMG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bZj2IMycJv3UBwSTDPMEzha-6mnHBD1r
"""

# !pip install botnoi==0.2.1


import botnoi as bn

from botnoi import scrape as sc
from botnoi import cv
import os

def extractimagefeat(query):
  #create folder
  foldername = 'images/'+query
  isdir = os.path.isdir(foldername) 
  #check if folder exist
  if not isdir:
    #create directory
    os.makedirs(foldername)
  #get images from google search
  imglist = sc.get_image_urls(query)
  i = 1
  for img in imglist[0:30]:
    #extract image features from each images and save to files
    try:
      print(i)
      #create image path
      savepath = foldername + '/' + str(i)+'.p'
      a = cv.image(img)
      a.getresnet50()
      a.save(savepath)
      i = i + 1
    except:
      pass
  return 'complete'

extractimagefeat('ตลาดรถไฟหนองคาย')



import glob
import pandas as pd
import pickle

def createdataset():
  imgfolder = glob.glob('images/*')
  dataset = []
  for cls in imgfolder:
    clsset = pd.DataFrame()
    pList = glob.glob(cls+'/*')
    featvec = []
    for p in pList:
      dat = pickle.load(open(p,'rb'))
      featvec.append(dat.resnet50)

    clsset['feature'] = featvec
    cls = cls.split('/')[-1]
    clsset['label'] = cls
    dataset.append(clsset)
  return pd.concat(dataset,axis=0)

dataset = createdataset()#สร้าง Dataset

# dataset

imgfolder = glob.glob('images/*')
for cls in imgfolder:
  imgList = glob.glob(cls+'/*')
imgList



from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.svm import LinearSVC
def trainmodel(dataset,modfile=''):
  trainfeat, testfeat, trainlabel, testlabel = train_test_split(dataset['feature'], dataset['label'], test_size=0.33, random_state=42)
  clf = LinearSVC()
  mod = clf.fit(np.vstack(trainfeat.values),trainlabel.values)
  res = mod.predict(np.vstack(testfeat.values))
  if modfile!='':
    pickle.dump(mod,open(modfile,'wb'))
  acc = sum(res == testlabel)/len(res)
  return mod,acc

mod,acc = trainmodel(dataset,'mymod.mod')

# output function
modFile = 'mymod.mod'
mod = pickle.load(open(modFile,'rb'))



@app.get("/imgurl/{text}")
def predicting(imgurl):
  a = cv.image(imgurl)
  feat = a.getresnet50()
  res = mod.predict([feat])
  return {"คุณอยู่ที่":res}


if __name__ == '__main__':
   import uvicorn
   uvicorn.run(app, host="localhost", port=5000, debug=True) 
